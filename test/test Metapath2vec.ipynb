{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70654efd-6f91-4218-902f-1ae79ec06a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\anaconda3\\envs\\GML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to ./openhgnn/dataset\\ohgbn-acm\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from openhgnn.dataset.NodeClassificationDataset import OHGB_NodeClassification\n",
    "from dgl.nn import MetaPath2Vec\n",
    "from torch.optim import SparseAdam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "acm = OHGB_NodeClassification(\n",
    "    dataset_name=\"ohgbn-acm\", raw_dir=\"./dataset\", logger=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78189793-eaaf-4e09-8e1e-311472bde032",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = acm.g\n",
    "meta_paths_dict = acm.meta_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5317214-485b-4fb6-a247-d7881d355af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openhgnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b56fcff-5518-4f89-a082-a84eaac2b7fb",
   "metadata": {},
   "source": [
    "## test Mp2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f523e301-af1f-46bf-a375-1b911802b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2v_negative_size = 5\n",
    "m2v_emb_dim = 128\n",
    "m2v_window_size = 3\n",
    "m2v_lr = 0.001\n",
    "\n",
    "m2v_batch_size = 256\n",
    "m2v_epoch = 20\n",
    "\n",
    "# m2v_rw_walk_length= 10\n",
    "# m2v_rw_walks_per_node= 3\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "def train_mp2vec(\n",
    "    hg,\n",
    "    category,\n",
    "    metapaths_dict,\n",
    "    mp2vec_feat_dim,\n",
    "    mp2vec_window_size,\n",
    "    mp2vec_negative_size,\n",
    "    mp2vec_train_lr,\n",
    "    mp2vec_train_epoch,\n",
    "    mp2vec_batch_size,\n",
    "):\n",
    "    hg = hg.to(device)\n",
    "    num_nodes = hg.num_nodes(category)\n",
    "    embs = torch.zeros(num_nodes,mp2vec_feat_dim).to(device)\n",
    "    \n",
    "    # for each metapath\n",
    "    for mp_name, mp in metapaths_dict.items():\n",
    "        print(\"Metapath:\", mp_name)\n",
    "        m2v_model = MetaPath2Vec(\n",
    "            hg, mp, mp2vec_window_size, mp2vec_feat_dim, mp2vec_negative_size\n",
    "        ).to(device)\n",
    "        m2v_model.train()\n",
    "        dataloader = DataLoader(\n",
    "            torch.arange(num_nodes),\n",
    "            batch_size=mp2vec_batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=m2v_model.sample,\n",
    "        )\n",
    "        optimizer = SparseAdam(m2v_model.parameters(), lr=mp2vec_train_lr)\n",
    "        for _ in tqdm(range(mp2vec_train_epoch)):\n",
    "            for pos_u, pos_v, neg_v in dataloader:\n",
    "                loss = m2v_model(pos_u.to(device), pos_v.to(device), neg_v.to(device))\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # get the embeddings\n",
    "        nids = torch.LongTensor(m2v_model.local_to_global_nid[category]).to(device)\n",
    "        emb = m2v_model.node_embed(nids)\n",
    "        # embs.append(emb)\n",
    "        embs+=emb\n",
    "\n",
    "        del m2v_model, nids, pos_u, pos_v, neg_v\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # concat these emb of each metapath\n",
    "    # return torch.concat(embs, dim=1).detach(),\n",
    "    return embs/len(metapaths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f32eb64-3bfe-4ada-9c69-22c149cc8734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metapath: PAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [00:02<00:00, 1186.36it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metapath: PSP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3025/3025 [00:02<00:00, 1224.54it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 10.26it/s]\n"
     ]
    }
   ],
   "source": [
    "mp2vec_feat = train_mp2vec(\n",
    "    hg,\n",
    "    \"paper\",\n",
    "    metapaths_dict=meta_paths_dict,\n",
    "    mp2vec_feat_dim=m2v_emb_dim,\n",
    "    mp2vec_window_size=m2v_window_size,\n",
    "    mp2vec_negative_size=m2v_negative_size,\n",
    "    mp2vec_train_lr=m2v_lr,\n",
    "    mp2vec_train_epoch=m2v_epoch,\n",
    "    mp2vec_batch_size=m2v_batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd920a19-3021-4ddc-9748-709d7929d36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3025, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp2vec_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee4958bb-d2c3-406e-841c-ea08db98bb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0611, -0.0082,  0.0148,  ..., -0.0573, -0.0157, -0.0115],\n",
       "        [ 0.0560, -0.0079,  0.0225,  ..., -0.0509, -0.0034, -0.0080],\n",
       "        [ 0.0632, -0.0057,  0.0166,  ..., -0.0595, -0.0013, -0.0015],\n",
       "        ...,\n",
       "        [ 0.0666, -0.0157,  0.0204,  ..., -0.0679, -0.0094, -0.0078],\n",
       "        [ 0.0459, -0.0072,  0.0072,  ..., -0.0501, -0.0030, -0.0004],\n",
       "        [ 0.0994,  0.0335, -0.0345,  ..., -0.1149, -0.0066,  0.0330]],\n",
       "       device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp2vec_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ebe45-5d13-4d35-a2b0-affffa63b3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775183e-ddcb-4758-90dd-e95672ee934b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911efc26-0e0b-4299-9078-865fad7cf44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdfab59-1f5a-48ee-98f2-93ddd1cda273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
