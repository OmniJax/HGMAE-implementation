{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70654efd-6f91-4218-902f-1ae79ec06a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\anaconda3\\envs\\GML\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to ./openhgnn/dataset\\ohgbn-acm\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dgl.nn import MetaPath2Vec\n",
    "from openhgnn.dataset.NodeClassificationDataset import OHGB_NodeClassification\n",
    "from torch.optim import SparseAdam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "acm = OHGB_NodeClassification(\n",
    "    dataset_name=\"ohgbn-acm\", raw_dir=\"./dataset\", logger=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78189793-eaaf-4e09-8e1e-311472bde032",
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = acm.g\n",
    "meta_paths_dict = acm.meta_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5317214-485b-4fb6-a247-d7881d355af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b56fcff-5518-4f89-a082-a84eaac2b7fb",
   "metadata": {},
   "source": [
    "## test Mp2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f523e301-af1f-46bf-a375-1b911802b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp2vec_negative_size = 5\n",
    "mp2vec_feat_dim = 128\n",
    "mp2vec_window_size = 5\n",
    "mp2vec_train_lr = 0.001\n",
    "mp2vec_batch_size = 256\n",
    "mp2vec_train_epoch = 20\n",
    "mp2vec_rw_walk_length = 10\n",
    "mp2vec_rw_walks_per_node = 3\n",
    "device = \"cuda\"\n",
    "\n",
    "\n",
    "def train_mp2vec(\n",
    "    hg,\n",
    "    category,\n",
    "    metapaths_dict,\n",
    "    mp2vec_feat_dim,\n",
    "    mp2vec_window_size,\n",
    "    mp2vec_negative_size,\n",
    "    mp2vec_rw_walk_length,\n",
    "    mp2vec_rw_walks_per_node,\n",
    "    mp2vec_train_lr,\n",
    "    mp2vec_train_epoch,\n",
    "    mp2vec_batch_size,\n",
    "):\n",
    "    hg = hg.to(device)\n",
    "    num_nodes = hg.num_nodes(category)\n",
    "\n",
    "    # metapath for metapath2vec model\n",
    "    Mp4Mp2Vec = []\n",
    "    mp_nodes_seq = []\n",
    "    for mp_name, mp in acm.meta_paths_dict.items():\n",
    "        Mp4Mp2Vec += mp\n",
    "        assert (mp[0][0]==mp[-1][-1]), \"The start node type and the end one in metapath should be the same.\"\n",
    "    \n",
    "    x=max(mp2vec_rw_walk_length//(len(Mp4Mp2Vec)+1),1)\n",
    "    Mp4Mp2Vec*=x\n",
    "    \n",
    "    for mp in Mp4Mp2Vec:\n",
    "        mp_nodes_seq.append(mp[0])\n",
    "    mp_nodes_seq.append(mp[-1])\n",
    "    assert (\n",
    "        mp_nodes_seq[0] == mp_nodes_seq[-1]\n",
    "    ), \"The start node type and the end one in metapath should be the same.\"\n",
    "    print(\"Metapath for training mp2vec models:\", mp_nodes_seq)\n",
    "\n",
    "    m2v_model = MetaPath2Vec(\n",
    "        hg, Mp4Mp2Vec, mp2vec_window_size, mp2vec_feat_dim, mp2vec_negative_size\n",
    "    ).to(device)\n",
    "    m2v_model.train()\n",
    "    dataloader = DataLoader(\n",
    "        list(range(num_nodes)) * mp2vec_rw_walks_per_node,\n",
    "        batch_size=mp2vec_batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=m2v_model.sample,\n",
    "    )\n",
    "    optimizer = SparseAdam(m2v_model.parameters(), lr=mp2vec_train_lr)\n",
    "    for _ in tqdm(range(mp2vec_train_epoch)):\n",
    "        for pos_u, pos_v, neg_v in dataloader:\n",
    "            loss = m2v_model(pos_u.to(device), pos_v.to(device), neg_v.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # get the embeddings\n",
    "    nids = torch.LongTensor(m2v_model.local_to_global_nid[category]).to(device)\n",
    "    emb = m2v_model.node_embed(nids)\n",
    "\n",
    "    del m2v_model, nids, pos_u, pos_v, neg_v\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    return emb.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b87ae-1ae5-49d4-8c1e-a5948f938dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7f32eb64-3bfe-4ada-9c69-22c149cc8734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metapath for training mp2vec models: ['paper', 'author', 'paper', 'subject', 'paper']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [00:01<00:00, 1623.98it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.00it/s]\n"
     ]
    }
   ],
   "source": [
    "mp2vec_feat = train_mp2vec(\n",
    "    hg,\n",
    "    \"paper\",\n",
    "    metapaths_dict=meta_paths_dict,\n",
    "    mp2vec_feat_dim=mp2vec_feat_dim,\n",
    "    mp2vec_window_size=mp2vec_window_size,\n",
    "    mp2vec_negative_size=mp2vec_negative_size,\n",
    "    mp2vec_train_lr=mp2vec_train_lr,\n",
    "    mp2vec_train_epoch=mp2vec_train_epoch,\n",
    "    mp2vec_batch_size=mp2vec_batch_size,\n",
    "    mp2vec_rw_walks_per_node=mp2vec_rw_walks_per_node,\n",
    "    mp2vec_rw_walk_length=mp2vec_rw_walk_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fd920a19-3021-4ddc-9748-709d7929d36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3025, 128])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp2vec_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee4958bb-d2c3-406e-841c-ea08db98bb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1002,  0.1190,  0.0887,  ...,  0.0571,  0.1262, -0.0924],\n",
       "        [-0.0823,  0.1349,  0.0495,  ...,  0.0565,  0.1109, -0.0930],\n",
       "        [-0.1024,  0.0948,  0.0914,  ...,  0.0962,  0.0945, -0.0886],\n",
       "        ...,\n",
       "        [-0.1247,  0.1205,  0.1371,  ...,  0.0969,  0.0379, -0.0608],\n",
       "        [-0.1033,  0.0826,  0.1067,  ...,  0.0962,  0.1356, -0.0863],\n",
       "        [-0.3054, -0.0359,  0.2993,  ...,  0.2854,  0.3617, -0.1911]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp2vec_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ba2e6-89e9-4705-92c0-f0c53732eff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8d316-8dad-49f7-9d1e-3562945aadd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659439d-e8f9-4d2b-8f26-79d682b2c516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05ebe45-5d13-4d35-a2b0-affffa63b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk length of one random walk\n",
    "rw_length = 20\n",
    "# number of random walks per node\n",
    "rw_walks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6775183e-ddcb-4758-90dd-e95672ee934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp2vec_negative_size = 5\n",
    "mp2vec_feat_dim = 128\n",
    "mp2vec_window_size = 3\n",
    "mp2vec_train_lr = 0.001\n",
    "mp2vec_batch_size = 256\n",
    "mp2vec_train_epoch = 20\n",
    "mp2vec_rw_walk_length = 10\n",
    "mp2vec_rw_walks_per_node = 3\n",
    "device = \"cuda\"\n",
    "num_nodes = hg.num_nodes(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "911efc26-0e0b-4299-9078-865fad7cf44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [00:01<00:00, 2831.51it/s]\n"
     ]
    }
   ],
   "source": [
    "m2v_model = MetaPath2Vec(\n",
    "    hg, meta_paths_dict[\"PAP\"], m2v_window_size, m2v_emb_dim, m2v_negative_size\n",
    ")\n",
    "# dataloader = DataLoader(\n",
    "# torch.arange(num_nodes),\n",
    "#             batch_size=m2v_batch_size,\n",
    "#             shuffle=True,\n",
    "#             collate_fn=m2v_model.sample,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd4dfd93-b68d-4e62-b2aa-a73e68545a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4a73b1a8-f40e-4515-9b47-f7f1d8f38cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   0,    0,  734,    2, 1775],\n",
       "         [   1,    3,    1,    1,  223],\n",
       "         [   2,    9,  121,    6, 1650],\n",
       "         ...,\n",
       "         [3022,  725, 3022,    5, 2923],\n",
       "         [3023, 5906, 3023,    2, 1449],\n",
       "         [3024, 5910, 3024,    2,  346]]),\n",
       " tensor([1, 0, 1, 2, 1]))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dgl.sampling import random_walk\n",
    "\n",
    "random_walk(\n",
    "    hg,\n",
    "    torch.arange(hg.num_nodes('paper')),\n",
    "    metapath=(meta_paths_dict[\"PAP\"] + meta_paths_dict[\"PSP\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85262bf9-7507-4c1d-8968-425caa5bc5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e5a71-8684-4649-ab30-886df75cdfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d845b62e-8e5b-4368-928d-0582b2b5265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3025/3025 [00:01<00:00, 2832.75it/s]\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "Mp4Mp2V = []\n",
    "for mp_name, mp in meta_paths_dict.items():\n",
    "    Mp4Mp2V += mp\n",
    "m2v_model = MetaPath2Vec(\n",
    "    hg, Mp4Mp2V, mp2vec_window_size, mp2vec_feat_dim, mp2vec_negative_size\n",
    ").to(device)\n",
    "m2v_model.train()\n",
    "dataloader = DataLoader(\n",
    "    list(range(num_nodes)) * mp2vec_rw_walks_per_node,\n",
    "    batch_size=mp2vec_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=m2v_model.sample,\n",
    ")\n",
    "\n",
    "optimizer = SparseAdam(m2v_model.parameters(), lr=mp2vec_train_lr)\n",
    "for _ in tqdm(range(mp2vec_train_epoch)):\n",
    "    for pos_u, pos_v, neg_v in dataloader:\n",
    "        loss = m2v_model(pos_u.to(device), pos_v.to(device), neg_v.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9a30b-0507-42e9-88a0-275a170c6ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99239e-f0f4-43f5-8982-dbebd99b7cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc40d95b-9f12-4369-aa5e-83fc1ccd232e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac4479-6aba-4c8b-9a9c-12bed4be7c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "523327ea-d83c-4dd6-88be-073f5238c1dd",
   "metadata": {},
   "source": [
    "## openhgnn random_walk_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d066af2a-50b8-4bd8-bdcc-33f56afdbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openhgnn.sampler import random_walk_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1a07da45-1fc6-46a0-a36b-c2962064302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Softwares\\anaconda3\\envs\\GML\\lib\\site-packages\\openhgnn\\sampler\\random_walk_sampler.py:69: RuntimeWarning: divide by zero encountered in divide\n",
      "  self.discards = np.sqrt(t / f) + (t / f)\n"
     ]
    }
   ],
   "source": [
    "mp2vec_sampler = random_walk_sampler.RandomWalkSampler(\n",
    "    g=hg,\n",
    "    metapath=meta_paths_dict[\"PAP\"],\n",
    "    rw_walks=2,\n",
    "    window_size=m2v_window_size,\n",
    "    neg_size=m2v_negative_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "64f6ea11-bc76-456c-ae1e-21dc1cb41f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    mp2vec_sampler,\n",
    "    batch_size=m2v_batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=mp2vec_sampler.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5f08137f-87c4-4a71-87f0-81a98b3f9c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:01<00:00, 10.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, sample_batched in enumerate(tqdm(dataloader)):\n",
    "    if len(sample_batched[0]) > 1:\n",
    "        pos_u = sample_batched[0]\n",
    "        pos_v = sample_batched[1]\n",
    "        neg_v = sample_batched[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b01e7512-37ec-4958-9545-85fc97e52248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('paper', 'paper-author', 'author')\n",
      "('author', 'author-paper', 'paper')\n"
     ]
    }
   ],
   "source": [
    "for etype in meta_paths_dict[\"PAP\"]:\n",
    "    print(etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2ea9c9d7-bb49-4756-90b9-9af2bba708f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metapath = [hg.get_etype_id(etype) for etype in meta_paths_dict[\"PAP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a1811d-dd15-4666-bc2d-f2e6595f0c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507c673-2398-43e8-ae0b-671703a03b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
