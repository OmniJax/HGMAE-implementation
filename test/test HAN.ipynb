{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30eb5c8f-3efa-4fcd-9ccb-bf83743aba14",
   "metadata": {},
   "source": [
    "## 研究能不能直接将源码中的HAN用openhgnn的HAN来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86770730-ce48-4396-b9f3-d0fa3890fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "from openhgnn.dataset.NodeClassificationDataset import OHGB_NodeClassification\n",
    "from openhgnn.utils import extract_metapaths, get_ntypes_from_canonical_etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba0cd236-9bd6-4c69-9910-a53351048905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to ./openhgnn/dataset\\ohgbn-acm\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "acm = OHGB_NodeClassification(\n",
    "    dataset_name=\"ohgbn-acm\", raw_dir=\"./dataset\", logger=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4553d7-e760-4045-8c3f-04760d515714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获得的hg和meta_paths_dict，即用户输入\n",
    "hg = acm.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511327bd-2abf-46fe-884b-3a37c7d87bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原来就有的metapath\n",
      "{'paper': {'PAP': [('paper', 'paper-author', 'author'), ('author', 'author-paper', 'paper')], 'PSP': [('paper', 'paper-subject', 'subject'), ('subject', 'subject-paper', 'paper')]}, 'subject': {}, 'author': {}}\n",
      "\n",
      "加上extract的metapath\n",
      "{'paper': {'PAP': [('paper', 'paper-author', 'author'), ('author', 'author-paper', 'paper')], 'PSP': [('paper', 'paper-subject', 'subject'), ('subject', 'subject-paper', 'paper')]}, 'subject': {'mp0': [('subject', 'subject-paper', 'paper'), ('paper', 'paper-subject', 'subject')]}, 'author': {'mp0': [('author', 'author-paper', 'paper'), ('paper', 'paper-author', 'author')]}}\n"
     ]
    }
   ],
   "source": [
    "ntypes = get_ntypes_from_canonical_etypes(hg.canonical_etypes)\n",
    "ntype_meta_paths_dict = {}\n",
    "for ntype in ntypes:\n",
    "    ntype_meta_paths_dict[ntype] = {}\n",
    "    for meta_path_name, meta_path in acm.meta_paths_dict.items():\n",
    "        if meta_path[0][0] == ntype:\n",
    "            ntype_meta_paths_dict[ntype][meta_path_name] = meta_path\n",
    "print(\"原来就有的metapath\")\n",
    "print(ntype_meta_paths_dict)\n",
    "\n",
    "print(\"\\n加上extract的metapath\")\n",
    "for ntype, meta_paths_dict in ntype_meta_paths_dict.items():\n",
    "    if len(meta_paths_dict) == 0:\n",
    "        ntype_meta_paths_dict[ntype] = extract_metapaths(ntype, hg.canonical_etypes)\n",
    "print(ntype_meta_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f2294f-4daa-4e05-b83a-aa3efff4bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1902\n",
    "hidden_dim = 512\n",
    "out_dim = 256\n",
    "dropout = 0.5\n",
    "layer_num_heads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a16da0-7f09-4785-b45a-b0373e79cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from dgl.nn import GATConv\n",
    "from openhgnn.layers import MetapathConv\n",
    "from openhgnn.layers.macro_layer.SemanticConv import SemanticAttention\n",
    "from openhgnn.models import HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697ce79-2c18-4d35-b593-d3b73c98da57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c192bf9-3158-4ddf-bd58-d239a290fa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b197828-ea2e-41d5-b54a-12f2438327d5",
   "metadata": {},
   "source": [
    "openhgnn中HAN里的HANLayer\n",
    "```python\n",
    "class HANLayer:\n",
    "    def __init__(self, meta_paths_dict, in_dim, out_dim, layer_num_heads, dropout):\n",
    "        super(HANLayer, self).__init__()\n",
    "        self.meta_paths_dict = meta_paths_dict\n",
    "        semantic_attention = SemanticAttention(in_size=out_dim * layer_num_heads)\n",
    "        mods = nn.ModuleDict({mp: GATConv(in_dim, out_dim, layer_num_heads,\n",
    "                                          dropout, dropout, activation=F.elu,\n",
    "                                          allow_zero_in_degree=True) for mp in meta_paths_dict})\n",
    "        self.model = MetapathConv(meta_paths_dict, mods, semantic_attention)\n",
    "        self._cached_graph = None\n",
    "        self._cached_coalesced_graph = {}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # For full batch, it is a heterogeneous graph.\n",
    "        # For mini batch, it is a dict from mata path name to DGLBlock.\n",
    "\n",
    "        # mini batch\n",
    "        if isinstance(g, dict):\n",
    "            h = self.model(g, h)\n",
    "        \n",
    "        # full batch\n",
    "        else:\n",
    "            if self._cached_graph is None or self._cached_graph is not g:\n",
    "                self._cached_graph = g\n",
    "                self._cached_coalesced_graph.clear()\n",
    "                for mp, mp_value in self.meta_paths_dict.items():\n",
    "                    self._cached_coalesced_graph[mp] = dgl.metapath_reachable_graph(\n",
    "                        g, mp_value)\n",
    "            h = self.model(self._cached_coalesced_graph, h)\n",
    "        \n",
    "        return h\n",
    "```\n",
    "\n",
    "`if self._cached_graph is None or self._cached_graph is not g:`，这一步判断了g是否是以前的g，说明可以根据这个来改变masked_gs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df68ef1b-77d6-4244-be49-9871a35ea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = nn.ModuleDict(\n",
    "    {\n",
    "        mp: GATConv(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            layer_num_heads,\n",
    "            dropout,\n",
    "            dropout,\n",
    "            activation=F.elu,\n",
    "            allow_zero_in_degree=True,\n",
    "        )\n",
    "        for mp in acm.meta_paths_dict\n",
    "    }\n",
    ")\n",
    "semantic_attention = SemanticAttention(in_size=out_dim * layer_num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52088e5-0b16-4a5a-9087-119fe7ec8dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3025, num_edges=29436,\n",
      "      ndata_schemes={'pspap_m2v_emb': Scheme(shape=(64,), dtype=torch.float32), 'psp_m2v_emb': Scheme(shape=(64,), dtype=torch.float32), 'pap_m2v_emb': Scheme(shape=(64,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.uint8), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1902,), dtype=torch.float32), 'valid_mask': Scheme(shape=(), dtype=torch.uint8)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "# HAN的forward中，要将hg根据mp切片为DGLBlock\n",
    "\n",
    "_cached_coalesced_graph={}\n",
    "for mp_name, mp in acm.meta_paths_dict.items():\n",
    "    _cached_coalesced_graph[mp_name]=dgl.metapath_reachable_graph(hg,mp)\n",
    "\n",
    "# 这一步将hg转换为了dict{metapath_name:mp-based graph(DGLBlock)}\n",
    "print(_cached_coalesced_graph['PAP'])\n",
    "\n",
    "g_dict=_cached_coalesced_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea3917-9e23-4d79-a80d-a55cbbc986ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ad1f0b-aca3-4e40-ad6e-1c79232e0d8d",
   "metadata": {},
   "source": [
    "HAN中使用到了MetapathConv\n",
    "```python\n",
    "class MetapathConv(nn.Module):\n",
    "    def __init__(self, meta_paths_dict, mods, macro_func, **kargs):\n",
    "        super(MetapathConv, self).__init__()\n",
    "        # One GAT layer for each meta path based adjacency matrix\n",
    "        self.mods = mods\n",
    "        self.meta_paths_dict = meta_paths_dict\n",
    "        self.SemanticConv = macro_func\n",
    "\n",
    "    def forward(self, g_dict, h_dict):\n",
    "        outputs = {g.dsttypes[0]: [] for s, g in g_dict.items()}\n",
    "\n",
    "        for meta_path_name, meta_path in self.meta_paths_dict.items():\n",
    "            new_g = g_dict[meta_path_name]\n",
    "\n",
    "            # han minibatch\n",
    "            if h_dict.get(meta_path_name) is not None:\n",
    "                h = h_dict[meta_path_name][new_g.srctypes[0]]\n",
    "            # full batch\n",
    "            else:\n",
    "                h = h_dict[new_g.srctypes[0]]\n",
    "            outputs[new_g.dsttypes[0]].append(self.mods[meta_path_name](new_g, h).flatten(1))\n",
    "        # semantic_embeddings = th.stack(semantic_embeddings, dim=1)  # (N, M, D * K)\n",
    "        # Aggregate the results for each destination node type\n",
    "        rsts = {}\n",
    "        for ntype, ntype_outputs in outputs.items():\n",
    "            if len(ntype_outputs) != 0:\n",
    "                rsts[ntype] = self.SemanticConv(ntype_outputs)  # (N, D * K)\n",
    "        return rsts\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9c554f-f240-4089-9f47-7c7c2b11fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': [tensor([[ 1.2369e-01,  2.1195e-01,  6.5390e-02,  ...,  5.0411e-01,\n",
      "          6.5650e-02,  5.9255e-02],\n",
      "        [ 9.3733e-02,  3.3919e-01, -1.2487e-01,  ..., -6.4489e-02,\n",
      "          5.9769e-02,  1.0934e-03],\n",
      "        [-3.1773e-03,  3.4519e-01, -2.1395e-01,  ...,  7.7881e-01,\n",
      "         -6.4730e-01,  3.3984e-01],\n",
      "        ...,\n",
      "        [-5.9106e-02,  1.7093e-01, -1.5496e-01,  ...,  2.7477e-01,\n",
      "         -3.6291e-01,  1.0742e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5397e+00,  1.2451e+00, -5.2654e-01,  ..., -7.6962e-01,\n",
      "         -5.4486e-01,  6.1737e-01]]), tensor([[ 0.3007, -0.3414,  0.2625,  ..., -0.2552,  0.5438,  0.6403],\n",
      "        [ 0.1365, -0.3032,  0.1592,  ...,  0.0596, -0.1617,  0.0055],\n",
      "        [ 0.0649, -0.3340,  0.0734,  ...,  0.0293, -0.0823,  0.0672],\n",
      "        ...,\n",
      "        [-0.0101, -0.2234,  0.1407,  ...,  0.0283,  0.0506,  0.0115],\n",
      "        [ 0.0559, -0.3819,  0.0848,  ...,  0.0674, -0.0948,  0.0763],\n",
      "        [ 0.0502, -0.3515,  0.1024,  ...,  0.0511, -0.1012,  0.0718]])]}\n",
      "\n",
      "{'paper': tensor([[ 2.1471e-01, -7.2489e-02,  1.6674e-01,  ...,  1.1378e-01,\n",
      "          3.1142e-01,  3.5795e-01],\n",
      "        [ 1.1571e-01,  8.9699e-03,  2.1166e-02,  ..., -6.7963e-04,\n",
      "         -5.4082e-02,  3.3474e-03],\n",
      "        [ 3.1796e-02, -3.9478e-03, -6.6217e-02,  ...,  3.9351e-01,\n",
      "         -3.5687e-01,  1.9971e-01],\n",
      "        ...,\n",
      "        [-3.3930e-02, -3.1764e-02, -2.9481e-03,  ...,  1.4807e-01,\n",
      "         -1.5033e-01,  1.1114e-02],\n",
      "        [ 2.8722e-02, -1.9630e-01,  4.3573e-02,  ...,  3.4634e-02,\n",
      "         -4.8724e-02,  3.9200e-02],\n",
      "        [ 7.7406e-01,  4.2438e-01, -2.0322e-01,  ..., -3.4773e-01,\n",
      "         -3.1682e-01,  3.3689e-01]])}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = {g.dsttypes[0]: [] for s, g in g_dict.items()}\n",
    "    h_dict=hg.ndata[\"h\"]\n",
    "    for meta_path_name, meta_path in acm.meta_paths_dict.items():\n",
    "        new_g = g_dict[meta_path_name]\n",
    "    \n",
    "        # han minibatch\n",
    "        if h_dict.get(meta_path_name) is not None:\n",
    "            h = h_dict[meta_path_name][new_g.srctypes[0]]\n",
    "        # full batch\n",
    "        else:\n",
    "            h = h_dict[new_g.srctypes[0]]\n",
    "        outputs[new_g.dsttypes[0]].append(mods[meta_path_name](new_g, h).flatten(1))\n",
    "    print(outputs)\n",
    "    print()\n",
    "    # outputs是一个dict，属于paper的h，两条路径的聚合\n",
    "    rsts = {}\n",
    "    for ntype, ntype_outputs in outputs.items():\n",
    "        if len(ntype_outputs) != 0:\n",
    "            rsts[ntype] = semantic_attention(ntype_outputs)  # (N, D * K)\n",
    "    \n",
    "    print(rsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a2599-eea2-4747-919e-2c284409568b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bd41839-697e-418f-b303-9c1124951a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': tensor([[-0.1914, -0.1095, -0.2157,  ...,  0.1740,  0.3112,  0.0530],\n",
       "         [ 0.0835, -0.0785,  0.0708,  ...,  0.0902, -0.2457, -0.0730],\n",
       "         [-0.0413, -0.2275,  0.0222,  ...,  0.1695, -0.0542, -0.0831],\n",
       "         ...,\n",
       "         [-0.1407, -0.1075,  0.1988,  ...,  0.2088,  0.2244, -0.0304],\n",
       "         [-0.0643, -0.1892,  0.0636,  ...,  0.9898, -0.4565,  0.1926],\n",
       "         [ 0.0305, -0.1768,  0.0645,  ...,  0.0158, -0.0709,  0.0248]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接使用MetapathConv\n",
    "mpconv = MetapathConv(acm.meta_paths_dict, mods, semantic_attention)\n",
    "with torch.no_grad():\n",
    "    out=mpconv(g_dict, hg.ndata[\"h\"])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c768a917-efb7-45a4-a210-408982267679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3025, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['paper'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df8ddd-99ad-447f-86d8-4fbd4527cca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1332254-eabc-4fd5-bb71-7e62d081626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727bcaa2-d928-4374-b2dd-0a89eed9e16a",
   "metadata": {},
   "source": [
    "直接使用HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb5cf69-9c68-4bd3-ac69-9ffaa6ee1e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': {}, 'paper': {'PAP': [('paper', 'paper-author', 'author'), ('author', 'author-paper', 'paper')], 'PSP': [('paper', 'paper-subject', 'subject'), ('subject', 'subject-paper', 'paper')]}, 'subject': {}}\n"
     ]
    }
   ],
   "source": [
    "# openhgnn的HAN需要ntype_meta_paths_dict\n",
    "ntypes = get_ntypes_from_canonical_etypes(hg.canonical_etypes)\n",
    "\n",
    "\n",
    "\n",
    "ntype_meta_paths_dict = {}\n",
    "for ntype in ntypes:\n",
    "    ntype_meta_paths_dict[ntype] = {}\n",
    "    for meta_path_name, meta_path in acm.meta_paths_dict.items():\n",
    "        if meta_path[0][0] == ntype:\n",
    "            ntype_meta_paths_dict[ntype][meta_path_name] = meta_path\n",
    "print(ntype_meta_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1c2eeb-a8bf-4941-a44b-7c2b33df43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "han=HAN(ntype_meta_paths_dict,in_dim,hidden_dim,out_dim,[1],dropout=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9790fae-3717-4a8f-8191-8a408638b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': tensor([[ 0.1791, -0.0815, -0.1062,  ...,  0.1575,  0.0690,  0.0660],\n",
      "        [ 0.1339, -0.0788,  0.0339,  ...,  0.1558,  0.0770,  0.0683],\n",
      "        [ 0.2612,  0.0139, -0.1024,  ...,  0.1158,  0.0659,  0.0698],\n",
      "        ...,\n",
      "        [ 0.2748,  0.0620, -0.2164,  ...,  0.1530,  0.1074,  0.0810],\n",
      "        [ 0.3924,  0.0947, -0.0461,  ...,  0.0500,  0.0843,  0.0720],\n",
      "        [ 0.1138, -0.0535,  0.0126,  ...,  0.0484,  0.0270,  0.0715]])}\n",
      "torch.Size([3025, 256])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out=han.forward(hg,h_dict)\n",
    "    print(out)\n",
    "    print(out['paper'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4f907-8b16-4912-bcac-a365a5b53c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42a800-7331-4f38-ad57-8435645ee886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943114b-53c6-4900-a5f1-1b4e896ab2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1edceb-eaec-4c0e-8110-aa2c343ebae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
