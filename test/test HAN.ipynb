{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30eb5c8f-3efa-4fcd-9ccb-bf83743aba14",
   "metadata": {},
   "source": [
    "## 研究能不能直接将源码中的HAN用openhgnn的HAN来实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86770730-ce48-4396-b9f3-d0fa3890fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "from openhgnn.dataset.NodeClassificationDataset import OHGB_NodeClassification\n",
    "from openhgnn.utils import extract_metapaths, get_ntypes_from_canonical_etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0cd236-9bd6-4c69-9910-a53351048905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to ./openhgnn/dataset\\ohgbn-acm\n",
      "Done saving data into cached files.\n"
     ]
    }
   ],
   "source": [
    "acm = OHGB_NodeClassification(\n",
    "    dataset_name=\"ohgbn-acm\", raw_dir=\"./dataset\", logger=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4553d7-e760-4045-8c3f-04760d515714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集获得的hg和meta_paths_dict，即用户输入\n",
    "hg = acm.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "511327bd-2abf-46fe-884b-3a37c7d87bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原来就有的metapath\n",
      "{'paper': {'PAP': [('paper', 'paper-author', 'author'), ('author', 'author-paper', 'paper')], 'PSP': [('paper', 'paper-subject', 'subject'), ('subject', 'subject-paper', 'paper')]}, 'subject': {}, 'author': {}}\n",
      "\n",
      "加上extract的metapath\n",
      "{'paper': {'PAP': [('paper', 'paper-author', 'author'), ('author', 'author-paper', 'paper')], 'PSP': [('paper', 'paper-subject', 'subject'), ('subject', 'subject-paper', 'paper')]}, 'subject': {'mp0': [('subject', 'subject-paper', 'paper'), ('paper', 'paper-subject', 'subject')]}, 'author': {'mp0': [('author', 'author-paper', 'paper'), ('paper', 'paper-author', 'author')]}}\n"
     ]
    }
   ],
   "source": [
    "ntypes = get_ntypes_from_canonical_etypes(hg.canonical_etypes)\n",
    "ntype_meta_paths_dict = {}\n",
    "for ntype in ntypes:\n",
    "    ntype_meta_paths_dict[ntype] = {}\n",
    "    for meta_path_name, meta_path in acm.meta_paths_dict.items():\n",
    "        if meta_path[0][0] == ntype:\n",
    "            ntype_meta_paths_dict[ntype][meta_path_name] = meta_path\n",
    "print(\"原来就有的metapath\")\n",
    "print(ntype_meta_paths_dict)\n",
    "\n",
    "print(\"\\n加上extract的metapath\")\n",
    "for ntype, meta_paths_dict in ntype_meta_paths_dict.items():\n",
    "    if len(meta_paths_dict) == 0:\n",
    "        ntype_meta_paths_dict[ntype] = extract_metapaths(ntype, hg.canonical_etypes)\n",
    "print(ntype_meta_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f2294f-4daa-4e05-b83a-aa3efff4bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 1902\n",
    "hidden_dim = 512\n",
    "out_dim = 256\n",
    "dropout = 0.5\n",
    "layer_num_heads = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a16da0-7f09-4785-b45a-b0373e79cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from dgl.nn import GATConv\n",
    "from openhgnn.layers import MetapathConv\n",
    "from openhgnn.layers.macro_layer.SemanticConv import SemanticAttention\n",
    "from openhgnn.models import HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f697ce79-2c18-4d35-b593-d3b73c98da57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c192bf9-3158-4ddf-bd58-d239a290fa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b197828-ea2e-41d5-b54a-12f2438327d5",
   "metadata": {},
   "source": [
    "openhgnn中HAN里的HANLayer\n",
    "```python\n",
    "class HANLayer:\n",
    "    def __init__(self, meta_paths_dict, in_dim, out_dim, layer_num_heads, dropout):\n",
    "        super(HANLayer, self).__init__()\n",
    "        self.meta_paths_dict = meta_paths_dict\n",
    "        semantic_attention = SemanticAttention(in_size=out_dim * layer_num_heads)\n",
    "        mods = nn.ModuleDict({mp: GATConv(in_dim, out_dim, layer_num_heads,\n",
    "                                          dropout, dropout, activation=F.elu,\n",
    "                                          allow_zero_in_degree=True) for mp in meta_paths_dict})\n",
    "        self.model = MetapathConv(meta_paths_dict, mods, semantic_attention)\n",
    "        self._cached_graph = None\n",
    "        self._cached_coalesced_graph = {}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        # For full batch, it is a heterogeneous graph.\n",
    "        # For mini batch, it is a dict from mata path name to DGLBlock.\n",
    "\n",
    "        # mini batch\n",
    "        if isinstance(g, dict):\n",
    "            h = self.model(g, h)\n",
    "        \n",
    "        # full batch\n",
    "        else:\n",
    "            if self._cached_graph is None or self._cached_graph is not g:\n",
    "                self._cached_graph = g\n",
    "                self._cached_coalesced_graph.clear()\n",
    "                for mp, mp_value in self.meta_paths_dict.items():\n",
    "                    self._cached_coalesced_graph[mp] = dgl.metapath_reachable_graph(\n",
    "                        g, mp_value)\n",
    "            h = self.model(self._cached_coalesced_graph, h)\n",
    "        \n",
    "        return h\n",
    "```\n",
    "\n",
    "`if self._cached_graph is None or self._cached_graph is not g:`，这一步判断了g是否是以前的g，说明可以根据这个来改变masked_gs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df68ef1b-77d6-4244-be49-9871a35ea728",
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = nn.ModuleDict(\n",
    "    {\n",
    "        mp: GATConv(\n",
    "            in_dim,\n",
    "            out_dim,\n",
    "            layer_num_heads,\n",
    "            dropout,\n",
    "            dropout,\n",
    "            activation=F.elu,\n",
    "            allow_zero_in_degree=True,\n",
    "        )\n",
    "        for mp in acm.meta_paths_dict\n",
    "    }\n",
    ")\n",
    "semantic_attention = SemanticAttention(in_size=out_dim * layer_num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d52088e5-0b16-4a5a-9087-119fe7ec8dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=3025, num_edges=29436,\n",
      "      ndata_schemes={'pspap_m2v_emb': Scheme(shape=(64,), dtype=torch.float32), 'psp_m2v_emb': Scheme(shape=(64,), dtype=torch.float32), 'pap_m2v_emb': Scheme(shape=(64,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.uint8), 'test_mask': Scheme(shape=(), dtype=torch.uint8), 'label': Scheme(shape=(), dtype=torch.int64), 'h': Scheme(shape=(1902,), dtype=torch.float32), 'valid_mask': Scheme(shape=(), dtype=torch.uint8)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "# HAN的forward中，要将hg根据mp切片为DGLBlock\n",
    "\n",
    "_cached_coalesced_graph={}\n",
    "for mp_name, mp in acm.meta_paths_dict.items():\n",
    "    _cached_coalesced_graph[mp_name]=dgl.metapath_reachable_graph(hg,mp)\n",
    "\n",
    "# 这一步将hg转换为了dict{metapath_name:mp-based graph(DGLBlock)}\n",
    "print(_cached_coalesced_graph['PAP'])\n",
    "\n",
    "g_dict=_cached_coalesced_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea3917-9e23-4d79-a80d-a55cbbc986ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ad1f0b-aca3-4e40-ad6e-1c79232e0d8d",
   "metadata": {},
   "source": [
    "HAN中使用到了MetapathConv\n",
    "```python\n",
    "class MetapathConv(nn.Module):\n",
    "    def __init__(self, meta_paths_dict, mods, macro_func, **kargs):\n",
    "        super(MetapathConv, self).__init__()\n",
    "        # One GAT layer for each meta path based adjacency matrix\n",
    "        self.mods = mods\n",
    "        self.meta_paths_dict = meta_paths_dict\n",
    "        self.SemanticConv = macro_func\n",
    "\n",
    "    def forward(self, g_dict, h_dict):\n",
    "        outputs = {g.dsttypes[0]: [] for s, g in g_dict.items()}\n",
    "\n",
    "        for meta_path_name, meta_path in self.meta_paths_dict.items():\n",
    "            new_g = g_dict[meta_path_name]\n",
    "\n",
    "            # han minibatch\n",
    "            if h_dict.get(meta_path_name) is not None:\n",
    "                h = h_dict[meta_path_name][new_g.srctypes[0]]\n",
    "            # full batch\n",
    "            else:\n",
    "                h = h_dict[new_g.srctypes[0]]\n",
    "            outputs[new_g.dsttypes[0]].append(self.mods[meta_path_name](new_g, h).flatten(1))\n",
    "        # semantic_embeddings = th.stack(semantic_embeddings, dim=1)  # (N, M, D * K)\n",
    "        # Aggregate the results for each destination node type\n",
    "        rsts = {}\n",
    "        for ntype, ntype_outputs in outputs.items():\n",
    "            if len(ntype_outputs) != 0:\n",
    "                rsts[ntype] = self.SemanticConv(ntype_outputs)  # (N, D * K)\n",
    "        return rsts\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a9c554f-f240-4089-9f47-7c7c2b11fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': [tensor([[ 0.2036, -0.0361,  0.1997,  ..., -0.3058,  0.1649, -0.1130],\n",
      "        [ 0.3468, -0.3744, -0.1728,  ...,  0.1059, -0.3072, -0.2183],\n",
      "        [ 0.2422,  0.0169,  0.1996,  ..., -0.1124, -0.0155,  0.1981],\n",
      "        ...,\n",
      "        [ 0.1022,  0.1159,  0.2687,  ..., -0.2894,  0.0432,  0.2256],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7990,  0.2888,  0.8461,  ..., -0.8822,  0.4676, -0.3560]]), tensor([[ 0.6023, -0.0884,  0.8597,  ..., -0.5670,  0.2021, -0.0894],\n",
      "        [ 0.0379,  0.0165,  0.2483,  ..., -0.3006,  0.2311, -0.2632],\n",
      "        [ 0.0221,  0.0193,  0.1875,  ..., -0.2636,  0.1656, -0.2307],\n",
      "        ...,\n",
      "        [ 0.0624,  0.0572,  0.2304,  ..., -0.2181,  0.1100, -0.2251],\n",
      "        [ 0.0486, -0.0011,  0.1911,  ..., -0.2555,  0.1922, -0.2325],\n",
      "        [ 0.0262,  0.0360,  0.1845,  ..., -0.2480,  0.1602, -0.2313]])]}\n",
      "\n",
      "{'paper': tensor([[ 3.9548e-01, -6.1275e-02,  5.1738e-01,  ..., -4.3152e-01,\n",
      "          1.8284e-01, -1.0162e-01],\n",
      "        [ 1.9813e-01, -1.8625e-01,  2.9855e-02,  ..., -8.9736e-02,\n",
      "         -4.8100e-02, -2.3990e-01],\n",
      "        [ 1.3624e-01,  1.8052e-02,  1.9379e-01,  ..., -1.8517e-01,\n",
      "          7.1670e-02, -8.2602e-03],\n",
      "        ...,\n",
      "        [ 8.3065e-02,  8.7656e-02,  2.5025e-01,  ..., -2.5509e-01,\n",
      "          7.5314e-02,  8.6917e-03],\n",
      "        [ 2.3374e-02, -5.3455e-04,  9.1964e-02,  ..., -1.2297e-01,\n",
      "          9.2500e-02, -1.1188e-01],\n",
      "        [ 4.2704e-01,  1.6713e-01,  5.2766e-01,  ..., -5.7695e-01,\n",
      "          3.1963e-01, -2.9594e-01]])}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = {g.dsttypes[0]: [] for s, g in g_dict.items()}\n",
    "    h_dict=hg.ndata[\"h\"]\n",
    "    for meta_path_name, meta_path in acm.meta_paths_dict.items():\n",
    "        new_g = g_dict[meta_path_name]\n",
    "    \n",
    "        # han minibatch\n",
    "        if h_dict.get(meta_path_name) is not None:\n",
    "            h = h_dict[meta_path_name][new_g.srctypes[0]]\n",
    "        # full batch\n",
    "        else:\n",
    "            h = h_dict[new_g.srctypes[0]]\n",
    "        outputs[new_g.dsttypes[0]].append(mods[meta_path_name](new_g, h).flatten(1))\n",
    "    print(outputs)\n",
    "    print()\n",
    "    # outputs是一个dict，属于paper的h，两条路径的聚合\n",
    "    rsts = {}\n",
    "    for ntype, ntype_outputs in outputs.items():\n",
    "        if len(ntype_outputs) != 0:\n",
    "            rsts[ntype] = semantic_attention(ntype_outputs)  # (N, D * K)\n",
    "    \n",
    "    print(rsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284a2599-eea2-4747-919e-2c284409568b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bd41839-697e-418f-b303-9c1124951a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper': tensor([[ 0.4138, -0.0761,  0.4194,  ..., -0.2695,  0.1206, -0.3403],\n",
       "         [ 0.3455, -0.2130,  0.4541,  ..., -0.1536, -0.2452, -0.1454],\n",
       "         [ 0.4710, -0.1164,  0.7756,  ..., -0.1699, -0.0819,  0.0316],\n",
       "         ...,\n",
       "         [ 0.0126,  0.0516,  0.1142,  ..., -0.1452,  0.0434, -0.0517],\n",
       "         [ 0.1937, -0.0087,  0.3265,  ..., -0.2583, -0.0323, -0.0156],\n",
       "         [ 0.0401,  0.0018,  0.0983,  ..., -0.1294,  0.0705, -0.1208]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接使用MetapathConv\n",
    "mpconv = MetapathConv(acm.meta_paths_dict, mods, semantic_attention)\n",
    "with torch.no_grad():\n",
    "    out=mpconv(g_dict, hg.ndata[\"h\"])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c768a917-efb7-45a4-a210-408982267679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3025, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['paper'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df8ddd-99ad-447f-86d8-4fbd4527cca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1332254-eabc-4fd5-bb71-7e62d081626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727bcaa2-d928-4374-b2dd-0a89eed9e16a",
   "metadata": {},
   "source": [
    "## 直接使用HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbb5cf69-9c68-4bd3-ac69-9ffaa6ee1e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': {'PAP': [('paper', 'paper-author', 'author'), ('author', 'author-paper', 'paper')], 'PSP': [('paper', 'paper-subject', 'subject'), ('subject', 'subject-paper', 'paper')]}, 'subject': {}, 'author': {}}\n"
     ]
    }
   ],
   "source": [
    "# openhgnn的HAN需要ntype_meta_paths_dict\n",
    "ntypes = get_ntypes_from_canonical_etypes(hg.canonical_etypes)\n",
    "\n",
    "\n",
    "\n",
    "ntype_meta_paths_dict = {}\n",
    "for ntype in ntypes:\n",
    "    ntype_meta_paths_dict[ntype] = {}\n",
    "    for meta_path_name, meta_path in acm.meta_paths_dict.items():\n",
    "        if meta_path[0][0] == ntype:\n",
    "            ntype_meta_paths_dict[ntype][meta_path_name] = meta_path\n",
    "print(ntype_meta_paths_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c1c2eeb-a8bf-4941-a44b-7c2b33df43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "han=HAN(ntype_meta_paths_dict,in_dim,hidden_dim,out_dim,[1],dropout=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9790fae-3717-4a8f-8191-8a408638b4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paper': tensor([[ 3.1669e-02, -1.5434e-01,  6.7913e-02,  ..., -1.1997e-02,\n",
      "         -8.9962e-02,  1.2028e-01],\n",
      "        [ 1.0401e-01,  7.3429e-03,  1.1457e-02,  ..., -4.1890e-02,\n",
      "         -1.1310e-01,  4.2793e-02],\n",
      "        [ 1.5618e-01, -6.3225e-02, -9.1707e-02,  ...,  7.1752e-02,\n",
      "         -1.5045e-01,  1.2942e-01],\n",
      "        ...,\n",
      "        [ 5.5060e-02, -4.7810e-02,  1.2178e-01,  ...,  3.6551e-03,\n",
      "         -1.7644e-01, -2.6895e-02],\n",
      "        [ 4.6538e-02, -5.7068e-02, -2.5474e-05,  ...,  5.6420e-02,\n",
      "         -7.8086e-02,  3.3113e-02],\n",
      "        [ 5.6040e-02, -5.0592e-02, -1.4845e-03,  ...,  5.4366e-02,\n",
      "         -8.4831e-02,  3.6234e-02]])}\n",
      "torch.Size([3025, 256])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out=han.forward(hg,h_dict)\n",
    "    print(out)\n",
    "    print(out['paper'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4f907-8b16-4912-bcac-a365a5b53c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42a800-7331-4f38-ad57-8435645ee886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1943114b-53c6-4900-a5f1-1b4e896ab2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1edceb-eaec-4c0e-8110-aa2c343ebae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa34686-eb72-45dd-87c3-605ab3a164c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
