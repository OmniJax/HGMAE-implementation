{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "b9b421be-06d0-470e-bdee-8e83ca1bacd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch as th\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "2ffd1090-66f9-49b3-aa46-8c126effa7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "ac9e9713-b8fc-4e93-ba84-78b356a50a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = data_folder + \"acm/\"\n",
    "label = np.load(path + \"labels.npy\")\n",
    "nei_a = np.load(path + \"nei_a.npy\", allow_pickle=True)\n",
    "nei_s = np.load(path + \"nei_s.npy\", allow_pickle=True)\n",
    "# 源码在此步骤划分了[20,40,60]\n",
    "type_num = [4019, 7167, 60]\n",
    "ratio = [20, 40, 60]\n",
    "feat_p = sp.load_npz(path + \"p_feat.npz\")\n",
    "feat_a = sp.eye(type_num[1])\n",
    "feat_s = sp.eye(type_num[2])\n",
    "\n",
    "pap = sp.load_npz(path + \"pap.npz\")\n",
    "psp = sp.load_npz(path + \"psp.npz\")\n",
    "pos = sp.load_npz(path + \"pos.npz\")\n",
    "\n",
    "train = [np.load(path + \"train_\" + str(i) + \".npy\") for i in ratio]\n",
    "test = [np.load(path + \"test_\" + str(i) + \".npy\") for i in ratio]\n",
    "val = [np.load(path + \"val_\" + str(i) + \".npy\") for i in ratio]\n",
    "\n",
    "label = th.LongTensor(label)\n",
    "nei_a = [th.LongTensor(i) for i in nei_a]\n",
    "nei_s = [th.LongTensor(i) for i in nei_s]\n",
    "\n",
    "# 源码此步preprocess_features\n",
    "feat_p = th.FloatTensor(feat_p.todense())\n",
    "feat_a = th.FloatTensor(feat_a.todense())\n",
    "feat_s = th.FloatTensor(feat_s.todense())\n",
    "\n",
    "pap = th.FloatTensor(pap.todense()).to_sparse()\n",
    "psp = th.FloatTensor(psp.todense()).to_sparse()\n",
    "pos = th.FloatTensor(pos.todense()).to_sparse()\n",
    "\n",
    "train = [th.LongTensor(i) for i in train]\n",
    "val = [th.LongTensor(i) for i in val]\n",
    "test = [th.LongTensor(i) for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "92c640c5-4e86-47ea-8031-769323a82d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj\n",
    "neis = [nei_a, nei_s]\n",
    "links = []\n",
    "for src, nei in enumerate(neis):\n",
    "    dst_array_concat = th.concatenate(nei)  # .unsqueeze(0)\n",
    "    src_array_concat = []\n",
    "    for src_id, dst_array in enumerate(nei):\n",
    "        src_array_concat.extend([src_id] * len(dst_array))\n",
    "    src_array_concat = th.tensor(src_array_concat)  # .unsqueeze(0)\n",
    "    index = th.vstack([src_array_concat, dst_array_concat])\n",
    "    links.append(index)\n",
    "    index = th.vstack([dst_array_concat, src_array_concat])\n",
    "    links.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "cad18aa8-52bb-406e-a605-ee1b0f27c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    (\"paper\", \"paper-author\", \"author\"): (links[0][0], links[0][1]),\n",
    "    (\"author\", \"author-paper\", \"paper\"): (links[1][0], links[1][1]),\n",
    "    (\"paper\", \"paper-subject\", \"subject\"): (links[2][0], links[2][1]),\n",
    "    (\"subject\", \"subject-paper\", \"paper\"): (links[3][0], links[3][1]),\n",
    "}\n",
    "\n",
    "\n",
    "meta_paths_dict = {\n",
    "    \"PAP\": [(\"paper\", \"paper-author\", \"author\"), (\"author\", \"author-paper\", \"paper\")],\n",
    "    \"PSP\": [\n",
    "        (\"paper\", \"paper-subject\", \"subject\"),\n",
    "        (\"subject\", \"subject-paper\", \"paper\"),\n",
    "    ],\n",
    "}\n",
    "\n",
    "hg = dgl.heterograph(data_dict)\n",
    "\n",
    "hg.nodes[\"paper\"].data[\"h\"] = feat_p\n",
    "hg.nodes[\"paper\"].data[\"label\"] = label\n",
    "\n",
    "hg.nodes[\"author\"].data[\"h\"] = feat_a\n",
    "hg.nodes[\"subject\"].data[\"h\"] = feat_s\n",
    "\n",
    "ratio=[20,40,60]\n",
    "for i,r in enumerate(ratio):\n",
    "    mask=th.zeros(4019).bool()\n",
    "    mask[train[i]]=True\n",
    "    hg.nodes['paper'].data['train_%d'%r]=mask\n",
    "\n",
    "    mask=th.zeros(4019).bool()\n",
    "    mask[val[i]]=True\n",
    "    hg.nodes['paper'].data['val_%d'%r]=mask\n",
    "\n",
    "    mask=th.zeros(4019).bool()\n",
    "    mask[test[i]]=True\n",
    "    hg.nodes['paper'].data['test_%d'%r]=mask\n",
    "\n",
    "dgl.save_graphs('./data/acm4hgmae.bin',hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7b990-8762-45d1-a4ed-a884fb31c50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbd73a-c2c5-4cd2-b328-03750d5b6d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493e6e5-7eed-4b9a-8d94-b157c09d4d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4f423-54c6-4978-bd5c-e8785db81ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GML",
   "language": "python",
   "name": "gml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
